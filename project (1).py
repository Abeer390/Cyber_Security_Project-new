# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JzRY5fmv0VkPkslRfDm5yySMQYrnBNyU
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.regularizers import l2

# Step 1: Load Dataset
file_path = "/content/drive/MyDrive/Colab Notebooks/IIoT_Malware_Timeseries_Dataset.csv"
data = pd.read_csv(file_path)

data.info()

# Step 2: Preprocess Dataset
# Convert datetime columns to numeric (if any)
for col in data.columns:
    if pd.api.types.is_datetime64_any_dtype(data[col]) or pd.to_datetime(data[col], errors='coerce').notnull().all():
        data[col] = pd.to_datetime(data[col], errors='coerce').astype('int64') // 10**9

# Handle missing values
for col in data.columns:
    if data[col].dtype == 'object':
        data[col].fillna(data[col].mode()[0], inplace=True)  # Fill categorical columns with mode
    else:
        data[col].fillna(data[col].mean(), inplace=True)  # Fill numeric columns with mean

# Encode categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns
label_encoders = {}
for col in categorical_columns:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

# Step 3: Prepare Features and Target
X = data.drop(columns=['Label'])  # Replace 'Attack Type' with the actual target column name
y = data['Label']

# Normalize features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Reshape target for CNN compatibility (One-hot encode for multi-class classification)
if len(y.unique()) > 2:
    y = pd.get_dummies(y).values

# Split dataset
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Reshape X for CNN input
X_train = np.expand_dims(X_train, axis=-1)
X_val = np.expand_dims(X_val, axis=-1)
X_test = np.expand_dims(X_test, axis=-1)

# Step 4: Build CNN Model
model = Sequential([
    tf.keras.Input(shape=(X_train.shape[1], 1)),
    Conv1D(filters=64, kernel_size=3, activation="relu", kernel_regularizer=l2(0.01)),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),
    Conv1D(filters=128, kernel_size=3, activation="relu", kernel_regularizer=l2(0.01)),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),
    Flatten(),
    Dense(256, activation="relu", kernel_regularizer=l2(0.01)),
    Dropout(0.4),
    Dense(y_train.shape[1] if len(y_train.shape) > 1 else 1, activation="softmax" if len(y_train.shape) > 1 else "sigmoid")
])

# Step 5: Compile the Model
loss = "categorical_crossentropy" if len(y_train.shape) > 1 else "binary_crossentropy"
model.compile(optimizer="Adam", loss=loss, metrics=["accuracy"])

# Step 6: Train the Model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=16,
    verbose=1
)

# Step 7: Evaluate the Model
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# Plot training history
plt.figure(figsize=(12, 6))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()